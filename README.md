## 5. The Feasibility of Our Approach

In fact, our approach is aligned with the best practices available today:
- Define clear evaluation criteria (even if subjective),
- Apply them consistently,
- Use both human and AI judges,
- Try to minimize arbitrariness via detailed rubrics.

If anything, you could make it even better by:
- Validating our scoring rubric with small-scale human studies,
- Using more than one AI model as judge (ensemble judge),
- Reporting inter-rater reliability if multiple humans are scoring (e.g., using Cohen's kappa, Krippendorffâ€™s alpha).
